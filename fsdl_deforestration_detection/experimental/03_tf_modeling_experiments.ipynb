{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c688819034f544f61fe874a727958ca1369fb300f2b7f3eadc7aa7e0f1155810",
   "display_name": "Python 3.7.10 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TensorFlow modeling experiments\n",
    "---\n",
    "\n",
    "Notebook for initial experiments on modeling deforestation through TensorFlow and the [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/) dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import FBetaScore\n",
    "from tensorflow.keras import losses, optimizers, metrics\n",
    "from tqdm.keras import TqdmCallback\n",
    "from ipywidgets import interact\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../data/')\n",
    "sys.path.append('../modeling/')\n",
    "import data_utils\n",
    "from models import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet50'\n",
    "task = 'orig_labels'\n",
    "pretrain_dataset = 'bigearthnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def choose_model_and_task(chosen_model_type=['resnet50', 'pretrained_resnet50'], chosen_task=['orig_labels', 'deforestation']):\n",
    "    global model_type\n",
    "    global task\n",
    "    global pretrain_dataset\n",
    "    model_type, task = chosen_model_type, chosen_task\n",
    "    if chosen_model_type == 'pretrained_resnet50':\n",
    "        pretrain_dataset = 'bigearthnet'\n",
    "    else:\n",
    "        pretrain_dataset = None"
   ]
  },
  {
   "source": [
    "## Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create a dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(data_utils.DATA_PATH + data_utils.LABELS_PATH)\n",
    "labels_df = data_utils.encode_tags(labels_df, drop_tags_col=True)\n",
    "if task == 'deforestation':\n",
    "    labels_df = data_utils.add_deforestation_label(labels_df)\n",
    "    labels_df = labels_df[['image_name', 'deforestation']]\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data_utils.get_amazon_sample(labels_df))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataframe so that the generator has no required arguments\n",
    "def data_gen():\n",
    "    for i in data_utils.get_amazon_sample(labels_df):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'deforestation':\n",
    "    labels_shape = len(data_utils.TAGS)\n",
    "else:\n",
    "    labels_shape = None\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_gen, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=([256, 256, 3]), dtype=tf.float16),\n",
    "        tf.TensorSpec(shape=(labels_shape), dtype=tf.uint8)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "source": [
    "### Split into train, validation and test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(labels_df)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = dataset.take(int(0.9 * n_samples)), dataset.skip(int(0.9 * n_samples))\n",
    "train_set, val_set = train_set.skip(int(0.1 * n_samples)), train_set.take(int(0.1 * n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_set = val_set.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_set = test_set.batch(32).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch = train_set.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_set.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in single_batch:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Train models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Set the modeling configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(\n",
    "    pretrain_dataset=pretrain_dataset,\n",
    "    pooling='max',\n",
    "    task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.003\n",
    "opt = optimizers.Adam(learning_rate=lr)\n",
    "if task == 'orig_labels':\n",
    "    loss = losses.CategoricalCrossentropy(from_logits=True)\n",
    "else:\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = [\n",
    "    metrics.Accuracy(), \n",
    "    FBetaScore(num_classes=model.n_outputs, average='macro', beta=2.0)\n",
    "]"
   ]
  },
  {
   "source": [
    "### Test a model\n",
    "\n",
    "Overfit a model on a batch of a classification task, so as to confirm that it works."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(single_batch, epochs=100, verbose=0, callbacks=[TqdmCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}